{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1679b4a-044c-4364-ab36-eaf828aeeb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.33.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.4-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Collecting typing_extensions>=3.6.6 (from tensorflow)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.18.0-cp312-cp312-win_amd64.whl.metadata (35 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (10.4.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl (331.9 MB)\n",
      "   ---------------------------------------- 0.0/331.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/331.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/331.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/331.9 MB 1.3 MB/s eta 0:04:17\n",
      "   ---------------------------------------- 0.8/331.9 MB 1.0 MB/s eta 0:05:16\n",
      "   ---------------------------------------- 0.8/331.9 MB 1.0 MB/s eta 0:05:16\n",
      "   ---------------------------------------- 1.0/331.9 MB 915.5 kB/s eta 0:06:02\n",
      "   ---------------------------------------- 1.3/331.9 MB 987.4 kB/s eta 0:05:35\n",
      "   ---------------------------------------- 1.3/331.9 MB 987.4 kB/s eta 0:05:35\n",
      "   ---------------------------------------- 2.4/331.9 MB 1.4 MB/s eta 0:04:04\n",
      "   ---------------------------------------- 2.9/331.9 MB 1.6 MB/s eta 0:03:30\n",
      "   ---------------------------------------- 3.7/331.9 MB 1.8 MB/s eta 0:03:06\n",
      "    --------------------------------------- 4.2/331.9 MB 1.8 MB/s eta 0:03:04\n",
      "    --------------------------------------- 4.7/331.9 MB 1.9 MB/s eta 0:02:56\n",
      "    --------------------------------------- 6.0/331.9 MB 2.2 MB/s eta 0:02:29\n",
      "    --------------------------------------- 7.3/331.9 MB 2.6 MB/s eta 0:02:07\n",
      "    --------------------------------------- 7.6/331.9 MB 2.5 MB/s eta 0:02:12\n",
      "   - -------------------------------------- 8.7/331.9 MB 2.6 MB/s eta 0:02:05\n",
      "   - -------------------------------------- 9.4/331.9 MB 2.7 MB/s eta 0:01:58\n",
      "   - -------------------------------------- 9.7/331.9 MB 2.7 MB/s eta 0:02:01\n",
      "   - -------------------------------------- 10.2/331.9 MB 2.6 MB/s eta 0:02:04\n",
      "   - -------------------------------------- 11.3/331.9 MB 2.7 MB/s eta 0:01:58\n",
      "   - -------------------------------------- 11.8/331.9 MB 2.7 MB/s eta 0:01:58\n",
      "   - -------------------------------------- 12.1/331.9 MB 2.7 MB/s eta 0:02:00\n",
      "   - -------------------------------------- 12.8/331.9 MB 2.7 MB/s eta 0:01:59\n",
      "   - -------------------------------------- 13.6/331.9 MB 2.8 MB/s eta 0:01:56\n",
      "   - -------------------------------------- 15.2/331.9 MB 2.9 MB/s eta 0:01:49\n",
      "   - -------------------------------------- 15.7/331.9 MB 2.9 MB/s eta 0:01:49\n",
      "   - -------------------------------------- 16.3/331.9 MB 2.9 MB/s eta 0:01:48\n",
      "   -- ------------------------------------- 17.8/331.9 MB 3.1 MB/s eta 0:01:43\n",
      "   -- ------------------------------------- 19.7/331.9 MB 3.3 MB/s eta 0:01:36\n",
      "   -- ------------------------------------- 19.9/331.9 MB 3.3 MB/s eta 0:01:36\n",
      "   -- ------------------------------------- 21.2/331.9 MB 3.3 MB/s eta 0:01:35\n",
      "   -- ------------------------------------- 22.8/331.9 MB 3.4 MB/s eta 0:01:30\n",
      "   -- ------------------------------------- 23.6/331.9 MB 3.4 MB/s eta 0:01:30\n",
      "   -- ------------------------------------- 24.1/331.9 MB 3.4 MB/s eta 0:01:30\n",
      "   --- ------------------------------------ 25.2/331.9 MB 3.5 MB/s eta 0:01:29\n",
      "   --- ------------------------------------ 26.0/331.9 MB 3.5 MB/s eta 0:01:29\n",
      "   --- ------------------------------------ 26.7/331.9 MB 3.5 MB/s eta 0:01:28\n",
      "   --- ------------------------------------ 27.3/331.9 MB 3.5 MB/s eta 0:01:28\n",
      "   --- ------------------------------------ 28.0/331.9 MB 3.5 MB/s eta 0:01:28\n",
      "   --- ------------------------------------ 29.6/331.9 MB 3.6 MB/s eta 0:01:25\n",
      "   --- ------------------------------------ 31.2/331.9 MB 3.7 MB/s eta 0:01:22\n",
      "   --- ------------------------------------ 31.7/331.9 MB 3.6 MB/s eta 0:01:23\n",
      "   --- ------------------------------------ 33.0/331.9 MB 3.7 MB/s eta 0:01:21\n",
      "   ---- ----------------------------------- 34.1/331.9 MB 3.8 MB/s eta 0:01:20\n",
      "   ---- ----------------------------------- 34.3/331.9 MB 3.7 MB/s eta 0:01:21\n",
      "   ---- ----------------------------------- 34.6/331.9 MB 3.6 MB/s eta 0:01:22\n",
      "   ---- ----------------------------------- 35.4/331.9 MB 3.6 MB/s eta 0:01:22\n",
      "   ---- ----------------------------------- 36.2/331.9 MB 3.6 MB/s eta 0:01:22\n",
      "   ---- ----------------------------------- 36.4/331.9 MB 3.6 MB/s eta 0:01:23\n",
      "   ---- ----------------------------------- 36.7/331.9 MB 3.6 MB/s eta 0:01:23\n",
      "   ---- ----------------------------------- 37.2/331.9 MB 3.5 MB/s eta 0:01:24\n",
      "   ---- ----------------------------------- 37.7/331.9 MB 3.5 MB/s eta 0:01:24\n",
      "   ---- ----------------------------------- 37.7/331.9 MB 3.5 MB/s eta 0:01:24\n",
      "   ---- ----------------------------------- 38.3/331.9 MB 3.4 MB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 38.8/331.9 MB 3.4 MB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 39.3/331.9 MB 3.4 MB/s eta 0:01:27\n",
      "   ---- ----------------------------------- 39.6/331.9 MB 3.4 MB/s eta 0:01:27\n",
      "   ---- ----------------------------------- 40.1/331.9 MB 3.3 MB/s eta 0:01:28\n",
      "   ---- ----------------------------------- 40.6/331.9 MB 3.3 MB/s eta 0:01:28\n",
      "   ---- ----------------------------------- 41.4/331.9 MB 3.3 MB/s eta 0:01:27\n",
      "   ----- ---------------------------------- 41.9/331.9 MB 3.3 MB/s eta 0:01:28\n",
      "   ----- ---------------------------------- 43.0/331.9 MB 3.3 MB/s eta 0:01:27\n",
      "   ----- ---------------------------------- 44.3/331.9 MB 3.4 MB/s eta 0:01:26\n",
      "   ----- ---------------------------------- 44.6/331.9 MB 3.3 MB/s eta 0:01:26\n",
      "   ----- ---------------------------------- 45.1/331.9 MB 3.3 MB/s eta 0:01:27\n",
      "   ----- ---------------------------------- 46.1/331.9 MB 3.4 MB/s eta 0:01:25\n",
      "   ----- ---------------------------------- 47.2/331.9 MB 3.4 MB/s eta 0:01:25\n",
      "   ----- ---------------------------------- 47.4/331.9 MB 3.4 MB/s eta 0:01:25\n",
      "   ----- ---------------------------------- 48.0/331.9 MB 3.3 MB/s eta 0:01:26\n",
      "   ----- ---------------------------------- 49.3/331.9 MB 3.4 MB/s eta 0:01:24\n",
      "   ------ --------------------------------- 50.1/331.9 MB 3.4 MB/s eta 0:01:24\n",
      "   ------ --------------------------------- 50.6/331.9 MB 3.4 MB/s eta 0:01:24\n",
      "   ------ --------------------------------- 51.6/331.9 MB 3.4 MB/s eta 0:01:23\n",
      "   ------ --------------------------------- 53.5/331.9 MB 3.5 MB/s eta 0:01:21\n",
      "   ------ --------------------------------- 53.7/331.9 MB 3.4 MB/s eta 0:01:21\n",
      "   ------ --------------------------------- 54.3/331.9 MB 3.4 MB/s eta 0:01:21\n",
      "   ------ --------------------------------- 55.8/331.9 MB 3.5 MB/s eta 0:01:20\n",
      "   ------ --------------------------------- 57.4/331.9 MB 3.5 MB/s eta 0:01:18\n",
      "   ------ --------------------------------- 57.9/331.9 MB 3.5 MB/s eta 0:01:19\n",
      "   ------- -------------------------------- 58.7/331.9 MB 3.5 MB/s eta 0:01:18\n",
      "   ------- -------------------------------- 60.0/331.9 MB 3.6 MB/s eta 0:01:17\n",
      "   ------- -------------------------------- 60.8/331.9 MB 3.6 MB/s eta 0:01:17\n",
      "   ------- -------------------------------- 61.1/331.9 MB 3.5 MB/s eta 0:01:17\n",
      "   ------- -------------------------------- 61.9/331.9 MB 3.5 MB/s eta 0:01:17\n",
      "   ------- -------------------------------- 63.2/331.9 MB 3.6 MB/s eta 0:01:16\n",
      "   ------- -------------------------------- 63.7/331.9 MB 3.6 MB/s eta 0:01:16\n",
      "   ------- -------------------------------- 64.2/331.9 MB 3.5 MB/s eta 0:01:16\n",
      "   ------- -------------------------------- 65.5/331.9 MB 3.6 MB/s eta 0:01:15\n",
      "   -------- ------------------------------- 66.8/331.9 MB 3.6 MB/s eta 0:01:14\n",
      "   -------- ------------------------------- 67.4/331.9 MB 3.6 MB/s eta 0:01:14\n",
      "   -------- ------------------------------- 67.6/331.9 MB 3.6 MB/s eta 0:01:14\n",
      "   -------- ------------------------------- 68.7/331.9 MB 3.6 MB/s eta 0:01:14\n",
      "   -------- ------------------------------- 69.2/331.9 MB 3.6 MB/s eta 0:01:14\n",
      "   -------- ------------------------------- 69.5/331.9 MB 3.6 MB/s eta 0:01:14\n",
      "   -------- ------------------------------- 70.0/331.9 MB 3.5 MB/s eta 0:01:15\n",
      "   -------- ------------------------------- 70.5/331.9 MB 3.5 MB/s eta 0:01:15\n",
      "   -------- ------------------------------- 71.3/331.9 MB 3.5 MB/s eta 0:01:14\n",
      "   -------- ------------------------------- 71.8/331.9 MB 3.5 MB/s eta 0:01:14\n",
      "   -------- ------------------------------- 72.4/331.9 MB 3.5 MB/s eta 0:01:15\n",
      "   -------- ------------------------------- 72.9/331.9 MB 3.5 MB/s eta 0:01:15\n",
      "   -------- ------------------------------- 73.9/331.9 MB 3.5 MB/s eta 0:01:14\n",
      "   -------- ------------------------------- 74.2/331.9 MB 3.5 MB/s eta 0:01:14\n",
      "   --------- ------------------------------ 74.7/331.9 MB 3.5 MB/s eta 0:01:15\n",
      "   --------- ------------------------------ 76.0/331.9 MB 3.5 MB/s eta 0:01:14\n",
      "   --------- ------------------------------ 76.3/331.9 MB 3.5 MB/s eta 0:01:14\n",
      "   --------- ------------------------------ 76.5/331.9 MB 3.5 MB/s eta 0:01:14\n",
      "   --------- ------------------------------ 77.3/331.9 MB 3.5 MB/s eta 0:01:14\n",
      "   --------- ------------------------------ 78.9/331.9 MB 3.5 MB/s eta 0:01:13\n",
      "   --------- ------------------------------ 79.7/331.9 MB 3.5 MB/s eta 0:01:12\n",
      "   --------- ------------------------------ 80.0/331.9 MB 3.5 MB/s eta 0:01:13\n",
      "   --------- ------------------------------ 81.3/331.9 MB 3.5 MB/s eta 0:01:12\n",
      "   --------- ------------------------------ 82.1/331.9 MB 3.5 MB/s eta 0:01:11\n",
      "   --------- ------------------------------ 82.8/331.9 MB 3.5 MB/s eta 0:01:11\n",
      "   ---------- ----------------------------- 83.6/331.9 MB 3.5 MB/s eta 0:01:11\n",
      "   ---------- ----------------------------- 84.1/331.9 MB 3.5 MB/s eta 0:01:11\n",
      "   ---------- ----------------------------- 85.7/331.9 MB 3.5 MB/s eta 0:01:10\n",
      "   ---------- ----------------------------- 86.2/331.9 MB 3.5 MB/s eta 0:01:10\n",
      "   ---------- ----------------------------- 87.0/331.9 MB 3.5 MB/s eta 0:01:10\n",
      "   ---------- ----------------------------- 87.8/331.9 MB 3.5 MB/s eta 0:01:10\n",
      "   ---------- ----------------------------- 88.6/331.9 MB 3.5 MB/s eta 0:01:09\n",
      "   ---------- ----------------------------- 89.1/331.9 MB 3.5 MB/s eta 0:01:09\n",
      "   ---------- ----------------------------- 89.9/331.9 MB 3.5 MB/s eta 0:01:09\n",
      "   ---------- ----------------------------- 91.0/331.9 MB 3.5 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 91.8/331.9 MB 3.5 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 92.0/331.9 MB 3.5 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 93.1/331.9 MB 3.5 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 94.1/331.9 MB 3.6 MB/s eta 0:01:07\n",
      "   ----------- ---------------------------- 94.4/331.9 MB 3.5 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 94.9/331.9 MB 3.5 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 96.5/331.9 MB 3.6 MB/s eta 0:01:07\n",
      "   ----------- ---------------------------- 98.3/331.9 MB 3.6 MB/s eta 0:01:06\n",
      "   ----------- ---------------------------- 98.8/331.9 MB 3.6 MB/s eta 0:01:06\n",
      "   ----------- ---------------------------- 99.4/331.9 MB 3.6 MB/s eta 0:01:05\n",
      "   ------------ --------------------------- 100.7/331.9 MB 3.6 MB/s eta 0:01:05\n",
      "   ------------ --------------------------- 101.4/331.9 MB 3.6 MB/s eta 0:01:05\n",
      "   ------------ --------------------------- 101.7/331.9 MB 3.6 MB/s eta 0:01:05\n",
      "   ------------ --------------------------- 103.0/331.9 MB 3.6 MB/s eta 0:01:04\n",
      "   ------------ --------------------------- 104.3/331.9 MB 3.6 MB/s eta 0:01:03\n",
      "   ------------ --------------------------- 105.4/331.9 MB 3.6 MB/s eta 0:01:03\n",
      "   ------------ --------------------------- 105.9/331.9 MB 3.6 MB/s eta 0:01:03\n",
      "   ------------ --------------------------- 106.4/331.9 MB 3.6 MB/s eta 0:01:03\n",
      "   ------------- -------------------------- 108.0/331.9 MB 3.6 MB/s eta 0:01:02\n",
      "   ------------- -------------------------- 108.3/331.9 MB 3.6 MB/s eta 0:01:02\n",
      "   ------------- -------------------------- 109.1/331.9 MB 3.6 MB/s eta 0:01:02\n",
      "   ------------- -------------------------- 109.8/331.9 MB 3.7 MB/s eta 0:01:01\n",
      "   ------------- -------------------------- 110.6/331.9 MB 3.7 MB/s eta 0:01:01\n",
      "   ------------- -------------------------- 111.1/331.9 MB 3.7 MB/s eta 0:01:00\n",
      "   ------------- -------------------------- 111.4/331.9 MB 3.7 MB/s eta 0:01:00\n",
      "   ------------- -------------------------- 111.9/331.9 MB 3.7 MB/s eta 0:01:00\n",
      "   ------------- -------------------------- 112.7/331.9 MB 3.7 MB/s eta 0:00:59\n",
      "   ------------- -------------------------- 113.0/331.9 MB 3.7 MB/s eta 0:00:59\n",
      "   ------------- -------------------------- 113.8/331.9 MB 3.7 MB/s eta 0:00:59\n",
      "   ------------- -------------------------- 115.1/331.9 MB 3.7 MB/s eta 0:00:59\n",
      "   ------------- -------------------------- 115.3/331.9 MB 3.7 MB/s eta 0:00:59\n",
      "   ------------- -------------------------- 115.6/331.9 MB 3.7 MB/s eta 0:00:59\n",
      "   -------------- ------------------------- 116.4/331.9 MB 3.7 MB/s eta 0:00:59\n",
      "   -------------- ------------------------- 117.7/331.9 MB 3.7 MB/s eta 0:00:58\n",
      "   -------------- ------------------------- 119.0/331.9 MB 3.7 MB/s eta 0:00:58\n",
      "   -------------- ------------------------- 119.5/331.9 MB 3.7 MB/s eta 0:00:58\n",
      "   -------------- ------------------------- 120.6/331.9 MB 3.7 MB/s eta 0:00:58\n",
      "   -------------- ------------------------- 122.4/331.9 MB 3.8 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 122.7/331.9 MB 3.8 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 123.2/331.9 MB 3.8 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 124.3/331.9 MB 3.8 MB/s eta 0:00:56\n",
      "   --------------- ------------------------ 125.6/331.9 MB 3.8 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 125.8/331.9 MB 3.8 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 126.4/331.9 MB 3.8 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 127.1/331.9 MB 3.8 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 127.9/331.9 MB 3.7 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 128.2/331.9 MB 3.7 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 128.5/331.9 MB 3.7 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 128.7/331.9 MB 3.7 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 130.3/331.9 MB 3.7 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 130.8/331.9 MB 3.7 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 131.3/331.9 MB 3.6 MB/s eta 0:00:56\n",
      "   --------------- ------------------------ 132.1/331.9 MB 3.6 MB/s eta 0:00:56\n",
      "   ---------------- ----------------------- 132.9/331.9 MB 3.6 MB/s eta 0:00:55\n",
      "   ---------------- ----------------------- 133.4/331.9 MB 3.6 MB/s eta 0:00:55\n",
      "   ---------------- ----------------------- 134.5/331.9 MB 3.6 MB/s eta 0:00:55\n",
      "   ---------------- ----------------------- 135.8/331.9 MB 3.6 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 136.6/331.9 MB 3.7 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 137.1/331.9 MB 3.6 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 138.4/331.9 MB 3.6 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 140.0/331.9 MB 3.6 MB/s eta 0:00:53\n",
      "   ----------------- ---------------------- 141.3/331.9 MB 3.7 MB/s eta 0:00:53\n",
      "   ----------------- ---------------------- 141.8/331.9 MB 3.6 MB/s eta 0:00:53\n",
      "   ----------------- ---------------------- 143.4/331.9 MB 3.6 MB/s eta 0:00:52\n",
      "   ----------------- ---------------------- 144.7/331.9 MB 3.7 MB/s eta 0:00:51\n",
      "   ----------------- ---------------------- 145.0/331.9 MB 3.7 MB/s eta 0:00:51\n",
      "   ----------------- ---------------------- 146.0/331.9 MB 3.7 MB/s eta 0:00:51\n",
      "   ----------------- ---------------------- 147.8/331.9 MB 3.7 MB/s eta 0:00:50\n",
      "   ----------------- ---------------------- 148.6/331.9 MB 3.7 MB/s eta 0:00:49\n",
      "   ----------------- ---------------------- 149.2/331.9 MB 3.7 MB/s eta 0:00:49\n",
      "   ------------------ --------------------- 150.2/331.9 MB 3.8 MB/s eta 0:00:49\n",
      "   ------------------ --------------------- 151.3/331.9 MB 3.8 MB/s eta 0:00:48\n",
      "   ------------------ --------------------- 152.0/331.9 MB 3.8 MB/s eta 0:00:48\n",
      "   ------------------ --------------------- 152.6/331.9 MB 3.8 MB/s eta 0:00:48\n",
      "   ------------------ --------------------- 153.6/331.9 MB 3.8 MB/s eta 0:00:47\n",
      "   ------------------ --------------------- 155.2/331.9 MB 3.9 MB/s eta 0:00:46\n",
      "   ------------------ --------------------- 156.0/331.9 MB 3.9 MB/s eta 0:00:46\n",
      "   ------------------ --------------------- 156.8/331.9 MB 3.9 MB/s eta 0:00:45\n",
      "   ------------------- -------------------- 158.3/331.9 MB 3.9 MB/s eta 0:00:45\n",
      "   ------------------- -------------------- 159.9/331.9 MB 3.9 MB/s eta 0:00:44\n",
      "   ------------------- -------------------- 160.4/331.9 MB 4.0 MB/s eta 0:00:44\n",
      "   ------------------- -------------------- 161.5/331.9 MB 4.0 MB/s eta 0:00:44\n",
      "   ------------------- -------------------- 163.1/331.9 MB 4.0 MB/s eta 0:00:43\n",
      "   ------------------- -------------------- 164.1/331.9 MB 4.0 MB/s eta 0:00:42\n",
      "   ------------------- -------------------- 164.6/331.9 MB 4.0 MB/s eta 0:00:42\n",
      "   ------------------- -------------------- 165.9/331.9 MB 4.0 MB/s eta 0:00:42\n",
      "   -------------------- ------------------- 167.5/331.9 MB 4.0 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 168.6/331.9 MB 4.0 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 169.3/331.9 MB 4.1 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 169.9/331.9 MB 4.0 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 171.4/331.9 MB 4.1 MB/s eta 0:00:40\n",
      "   -------------------- ------------------- 172.0/331.9 MB 4.1 MB/s eta 0:00:40\n",
      "   -------------------- ------------------- 172.5/331.9 MB 4.0 MB/s eta 0:00:40\n",
      "   -------------------- ------------------- 173.5/331.9 MB 4.0 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 175.1/331.9 MB 4.0 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 175.9/331.9 MB 4.1 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 176.4/331.9 MB 4.0 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 177.2/331.9 MB 4.0 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 179.0/331.9 MB 4.0 MB/s eta 0:00:38\n",
      "   --------------------- ------------------ 179.3/331.9 MB 4.0 MB/s eta 0:00:38\n",
      "   --------------------- ------------------ 179.8/331.9 MB 4.0 MB/s eta 0:00:38\n",
      "   --------------------- ------------------ 181.1/331.9 MB 4.0 MB/s eta 0:00:38\n",
      "   --------------------- ------------------ 182.2/331.9 MB 4.0 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 183.2/331.9 MB 4.0 MB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 184.0/331.9 MB 4.0 MB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 185.1/331.9 MB 4.1 MB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 185.9/331.9 MB 4.1 MB/s eta 0:00:36\n",
      "   ---------------------- ----------------- 186.1/331.9 MB 4.0 MB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 187.2/331.9 MB 4.0 MB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 188.7/331.9 MB 4.1 MB/s eta 0:00:36\n",
      "   ---------------------- ----------------- 189.5/331.9 MB 4.1 MB/s eta 0:00:35\n",
      "   ---------------------- ----------------- 190.1/331.9 MB 4.1 MB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 190.8/331.9 MB 4.1 MB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 192.7/331.9 MB 4.1 MB/s eta 0:00:34\n",
      "   ----------------------- ---------------- 193.7/331.9 MB 4.1 MB/s eta 0:00:34\n",
      "   ----------------------- ---------------- 194.2/331.9 MB 4.1 MB/s eta 0:00:34\n",
      "   ----------------------- ---------------- 195.6/331.9 MB 4.2 MB/s eta 0:00:33\n",
      "   ----------------------- ---------------- 196.9/331.9 MB 4.2 MB/s eta 0:00:33\n",
      "   ----------------------- ---------------- 197.7/331.9 MB 4.2 MB/s eta 0:00:33\n",
      "   ----------------------- ---------------- 198.2/331.9 MB 4.2 MB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 199.0/331.9 MB 4.2 MB/s eta 0:00:32\n",
      "   ------------------------ --------------- 199.8/331.9 MB 4.2 MB/s eta 0:00:32\n",
      "   ------------------------ --------------- 200.5/331.9 MB 4.2 MB/s eta 0:00:32\n",
      "   ------------------------ --------------- 201.1/331.9 MB 4.2 MB/s eta 0:00:32\n",
      "   ------------------------ --------------- 202.4/331.9 MB 4.2 MB/s eta 0:00:31\n",
      "   ------------------------ --------------- 203.9/331.9 MB 4.3 MB/s eta 0:00:31\n",
      "   ------------------------ --------------- 205.0/331.9 MB 4.3 MB/s eta 0:00:30\n",
      "   ------------------------ --------------- 205.8/331.9 MB 4.3 MB/s eta 0:00:30\n",
      "   ------------------------ --------------- 207.1/331.9 MB 4.3 MB/s eta 0:00:30\n",
      "   ------------------------- -------------- 207.9/331.9 MB 4.3 MB/s eta 0:00:30\n",
      "   ------------------------- -------------- 208.4/331.9 MB 4.3 MB/s eta 0:00:29\n",
      "   ------------------------- -------------- 209.5/331.9 MB 4.2 MB/s eta 0:00:29\n",
      "   ------------------------- -------------- 210.8/331.9 MB 4.3 MB/s eta 0:00:29\n",
      "   ------------------------- -------------- 211.3/331.9 MB 4.3 MB/s eta 0:00:29\n",
      "   ------------------------- -------------- 211.8/331.9 MB 4.3 MB/s eta 0:00:29\n",
      "   ------------------------- -------------- 212.9/331.9 MB 4.3 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 213.9/331.9 MB 4.3 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 215.0/331.9 MB 4.3 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 215.5/331.9 MB 4.3 MB/s eta 0:00:28\n",
      "   -------------------------- ------------- 216.8/331.9 MB 4.3 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 217.6/331.9 MB 4.3 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 217.8/331.9 MB 4.3 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 218.4/331.9 MB 4.3 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 219.4/331.9 MB 4.3 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 219.9/331.9 MB 4.3 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 220.5/331.9 MB 4.3 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 221.0/331.9 MB 4.3 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 222.3/331.9 MB 4.3 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 224.1/331.9 MB 4.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 224.4/331.9 MB 4.3 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 225.4/331.9 MB 4.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 227.0/331.9 MB 4.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 228.1/331.9 MB 4.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 228.3/331.9 MB 4.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 229.1/331.9 MB 4.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 230.7/331.9 MB 4.3 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 231.5/331.9 MB 4.3 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 232.3/331.9 MB 4.3 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 233.3/331.9 MB 4.3 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 234.9/331.9 MB 4.3 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 235.9/331.9 MB 4.3 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 236.7/331.9 MB 4.3 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 237.5/331.9 MB 4.3 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 238.0/331.9 MB 4.3 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 238.6/331.9 MB 4.3 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 239.1/331.9 MB 4.3 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 240.4/331.9 MB 4.3 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 241.4/331.9 MB 4.3 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 242.0/331.9 MB 4.4 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 242.7/331.9 MB 4.4 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 244.1/331.9 MB 4.4 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 244.8/331.9 MB 4.4 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 245.1/331.9 MB 4.4 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 246.2/331.9 MB 4.4 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 246.7/331.9 MB 4.4 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 248.0/331.9 MB 4.4 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 248.3/331.9 MB 4.4 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 249.6/331.9 MB 4.4 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 250.9/331.9 MB 4.4 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 252.4/331.9 MB 4.4 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 253.0/331.9 MB 4.4 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 254.3/331.9 MB 4.4 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 255.9/331.9 MB 4.4 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 256.6/331.9 MB 4.5 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 257.4/331.9 MB 4.4 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 259.0/331.9 MB 4.4 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 260.6/331.9 MB 4.5 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 261.1/331.9 MB 4.5 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 261.6/331.9 MB 4.5 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 262.7/331.9 MB 4.5 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 263.2/331.9 MB 4.5 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 263.7/331.9 MB 4.5 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 264.5/331.9 MB 4.5 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 265.6/331.9 MB 4.5 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 266.3/331.9 MB 4.5 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 266.9/331.9 MB 4.5 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 267.6/331.9 MB 4.5 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 269.5/331.9 MB 4.6 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 270.5/331.9 MB 4.6 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 271.1/331.9 MB 4.5 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 272.4/331.9 MB 4.5 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 273.9/331.9 MB 4.6 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 274.5/331.9 MB 4.6 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 275.0/331.9 MB 4.6 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 276.0/331.9 MB 4.5 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 276.8/331.9 MB 4.5 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 277.3/331.9 MB 4.5 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 277.9/331.9 MB 4.5 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 279.2/331.9 MB 4.5 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 280.5/331.9 MB 4.5 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 280.8/331.9 MB 4.5 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 281.3/331.9 MB 4.4 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 282.9/331.9 MB 4.5 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 283.4/331.9 MB 4.5 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 283.6/331.9 MB 4.5 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 284.4/331.9 MB 4.4 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 285.5/331.9 MB 4.4 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 286.3/331.9 MB 4.5 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 286.8/331.9 MB 4.4 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 287.6/331.9 MB 4.4 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 288.6/331.9 MB 4.4 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 288.9/331.9 MB 4.4 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 289.7/331.9 MB 4.4 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 290.5/331.9 MB 4.3 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 292.0/331.9 MB 4.4 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 292.8/331.9 MB 4.4 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 293.3/331.9 MB 4.3 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 294.6/331.9 MB 4.3 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 295.7/331.9 MB 4.4 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 296.2/331.9 MB 4.3 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 297.3/331.9 MB 4.3 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 298.8/331.9 MB 4.3 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 299.6/331.9 MB 4.3 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 300.4/331.9 MB 4.3 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 301.7/331.9 MB 4.3 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 303.0/331.9 MB 4.4 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 303.0/331.9 MB 4.4 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 303.0/331.9 MB 4.4 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 304.6/331.9 MB 4.3 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 305.7/331.9 MB 4.3 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 306.2/331.9 MB 4.3 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 307.2/331.9 MB 4.3 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 308.3/331.9 MB 4.3 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 309.3/331.9 MB 4.3 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 309.9/331.9 MB 4.3 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 310.6/331.9 MB 4.3 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 312.0/331.9 MB 4.3 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 312.5/331.9 MB 4.3 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 313.3/331.9 MB 4.3 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 314.0/331.9 MB 4.3 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 314.3/331.9 MB 4.3 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 314.8/331.9 MB 4.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 315.4/331.9 MB 4.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 316.7/331.9 MB 4.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 318.8/331.9 MB 4.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 319.3/331.9 MB 4.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 320.1/331.9 MB 4.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 321.9/331.9 MB 4.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 323.0/331.9 MB 4.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 323.5/331.9 MB 4.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  324.5/331.9 MB 4.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  325.1/331.9 MB 4.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  325.3/331.9 MB 4.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  325.6/331.9 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  326.4/331.9 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  327.4/331.9 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  328.5/331.9 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  329.0/331.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  330.0/331.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.1/331.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.6/331.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 331.9/331.9 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.7.0-py3-none-any.whl (22 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.76.0-cp312-cp312-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.8/4.7 MB 8.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.0/4.7 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 1.6/4.7 MB 2.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 2.6/4.7 MB 3.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.2/4.7 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.5/4.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.5/1.5 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/26.4 MB 4.2 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 1.0/26.4 MB 2.3 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.6/26.4 MB 2.4 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 2.9/26.4 MB 3.7 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 3.9/26.4 MB 4.2 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 4.5/26.4 MB 3.6 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 5.8/26.4 MB 4.0 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 7.3/26.4 MB 4.6 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.7/26.4 MB 4.7 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 9.4/26.4 MB 4.6 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 11.0/26.4 MB 4.8 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 12.3/26.4 MB 5.1 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 12.8/26.4 MB 4.8 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 13.9/26.4 MB 4.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 15.5/26.4 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 17.0/26.4 MB 5.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 17.6/26.4 MB 5.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 18.1/26.4 MB 4.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 19.7/26.4 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 20.4/26.4 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 21.0/26.4 MB 4.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 22.3/26.4 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.9/26.4 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.4/26.4 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.4/26.4 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 4.7 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.4-cp312-cp312-win_amd64.whl (212 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.33.1-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.3/5.5 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.8/5.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.4/5.5 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.2/5.5 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 5.0 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached optree-0.18.0-cp312-cp312-win_amd64.whl (312 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, typing_extensions, termcolor, tensorboard-data-server, protobuf, opt_einsum, ml_dtypes, google_pasta, gast, astunparse, absl-py, optree, grpcio, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.7.0 google_pasta-0.2.0 grpcio-1.76.0 keras-3.12.0 libclang-18.1.1 ml_dtypes-0.5.4 namex-0.1.0 opt_einsum-3.4.0 optree-0.18.0 protobuf-6.33.1 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.2.0 typing_extensions-4.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\amand\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe and toco.exe are installed in 'C:\\Users\\amand\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.37.1 requires protobuf<6,>=3.20, but you have protobuf 6.33.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a638318a-5fdd-4e8e-80e7-715f096e5fcf",
   "metadata": {},
   "source": [
    "TOPIC 1: Understanding Pooling and Padding in CNN\n",
    "1. Describe the purpose and benefits of pooling in CNN.\n",
    "Explanation: Pooling (also known as subsampling) is a process used to reduce the spatial dimensions (width and height) of the feature maps produced by convolutional layers.\n",
    "Purpose: To progressively reduce the amount of parameters and computation in the network.\n",
    "Benefits:\n",
    "Dimensionality Reduction: It makes the model lighter and faster to train.\n",
    "Translation Invariance: It helps the model recognize features (like a cat's ear) regardless of exactly where they are located in the image.\n",
    "Prevents Overfitting: By removing precise spatial information, the model focuses on the existence of features rather than their exact location.\n",
    "2. Explain the difference between min pooling and max pooling.\n",
    "Explanation:\n",
    "Max Pooling: It selects the maximum value from the covered region (e.g., a 2x2 grid). It is the most common type because it captures the most prominent features (edges, textures).\n",
    "Min Pooling: It selects the minimum value from the region. It is rarely used but can be useful for selecting the darkest pixels in an image or suppressing bright noise.\n",
    "3. Discuss the concept of padding in CNN and its significance.\n",
    "Explanation: Padding involves adding extra pixels (usually with a value of 0) around the border of an input image or feature map before applying a convolution operation.\n",
    "Significance: Without padding, the image size shrinks with every convolutional layer. Eventually, the image would become too small (1x1). Padding allows us to build deeper networks by keeping the spatial dimensions constant. It also prevents the loss of information at the very edges of the image.\n",
    "4. Compare and contrast zero-padding and valid-padding.\n",
    "Explanation:\n",
    "Valid Padding (No Padding): No pixels are added. The filter only visits valid positions inside the original image.\n",
    "Effect: The output feature map is smaller than the input.\n",
    "Zero Padding (Same Padding): Rows and columns of zeros are added around the image borders.\n",
    "Effect: The output feature map usually remains the same size as the input (if stride is 1). This preserves the spatial resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3475889-40ac-4837-b321-85abe875bf60",
   "metadata": {},
   "source": [
    "TOPIC 2: Exploring LeNet\n",
    "1. Provide a brief overview of LeNet-5 architecture.\n",
    "Explanation: LeNet-5 is one of the earliest Convolutional Neural Networks, proposed by Yann LeCun in 1998. It was designed to recognize handwritten digits (specifically for the MNIST dataset). It is a relatively small network consisting of 7 layers (excluding the input).\n",
    "2. Describe the key components of LeNet-5 and their respective purposes.\n",
    "Explanation:\n",
    "Convolutional Layers (C1, C3, C5): To extract feature patterns from the input images using learnable filters.\n",
    "Sub-sampling (Average Pooling) Layers (S2, S4): To reduce the size of the feature maps. Note that LeNet originally used Average Pooling, not Max Pooling.\n",
    "Activation Function: LeNet used Tanh or Sigmoid activation functions (modern nets use ReLU).\n",
    "Fully Connected Layers (F6): To combine features for the final classification.\n",
    "Output Layer: A radial basis function (modern implementations use Softmax) to classify digits 09.\n",
    "3. Discuss the advantages and limitations of LeNet-5.\n",
    "Explanation:\n",
    "Advantages: It established the foundation for modern CNNs (Conv -> Pool -> FC structure). It is very efficient for simple tasks like digit recognition.\n",
    "Limitations: It struggles with complex, high-resolution color images. Because it used Sigmoid/Tanh activations, it suffered from the \"vanishing gradient\" problem, making it hard to train if the network were made deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dae40a0-8ae2-44c0-aac9-bc777642b1d4",
   "metadata": {},
   "source": [
    "4. Implement LeNet-5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95d22e34-35ee-44b4-a420-5485e935ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def LeNet5():\n",
    "    model = models.Sequential()\n",
    "    # Layer 1: Conv2D (6 filters, 5x5 kernel, Tanh activation)\n",
    "    model.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=(32, 32, 1), padding=\"same\"))\n",
    "    # Layer 2: Average Pooling\n",
    "    model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    # Layer 3: Conv2D (16 filters)\n",
    "    model.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    "    # Layer 4: Average Pooling\n",
    "    model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    # Flatten for FC layers\n",
    "    model.add(layers.Flatten())\n",
    "    # Layer 5: Fully Connected (120 nodes)\n",
    "    model.add(layers.Dense(120, activation='tanh'))\n",
    "    # Layer 6: Fully Connected (84 nodes)\n",
    "    model.add(layers.Dense(84, activation='tanh'))\n",
    "    # Output Layer (10 digits)\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f934c2f0-f9bc-4d02-a7f1-4cf08813706b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amand\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
       "\n",
       " conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> \n",
       "\n",
       " average_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,416</span> \n",
       "\n",
       " average_pooling2d_1                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                                                                 \n",
       "\n",
       " flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">69,240</span> \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">10,164</span> \n",
       "\n",
       " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">850</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " conv2d (\u001b[38;5;33mConv2D\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m6\u001b[0m)                        \u001b[38;5;34m156\u001b[0m \n",
       "\n",
       " average_pooling2d (\u001b[38;5;33mAveragePooling2D\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m6\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m16\u001b[0m)                     \u001b[38;5;34m2,416\u001b[0m \n",
       "\n",
       " average_pooling2d_1                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m)                           \u001b[38;5;34m0\u001b[0m \n",
       " (\u001b[38;5;33mAveragePooling2D\u001b[0m)                                                                 \n",
       "\n",
       " flatten (\u001b[38;5;33mFlatten\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)                           \u001b[38;5;34m69,240\u001b[0m \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)                            \u001b[38;5;34m10,164\u001b[0m \n",
       "\n",
       " dense_2 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                               \u001b[38;5;34m850\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,826</span> (323.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m82,826\u001b[0m (323.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,826</span> (323.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m82,826\u001b[0m (323.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Starting training...\n",
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.9344 - loss: 0.2198 - val_accuracy: 0.9674 - val_loss: 0.1037\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9731 - loss: 0.0876 - val_accuracy: 0.9782 - val_loss: 0.0714\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9810 - loss: 0.0614 - val_accuracy: 0.9799 - val_loss: 0.0636\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9846 - loss: 0.0491 - val_accuracy: 0.9829 - val_loss: 0.0526\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9883 - loss: 0.0380 - val_accuracy: 0.9813 - val_loss: 0.0583\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 1. Create the Model\n",
    "model = LeNet5()\n",
    "\n",
    "# Check if the model structure is correct\n",
    "model.summary()\n",
    "\n",
    "# 2. Compile the Model (Define how it learns)\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 3. Load the MNIST Dataset\n",
    "print(\"Loading data...\")\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# 4. Preprocessing\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Add a channel dimension (MNIST is grayscale, so we need 1 channel)\n",
    "# Shape changes from (60000, 28, 28) to (60000, 28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# Resize images from 28x28 to 32x32 (standard LeNet input size)\n",
    "x_train = tf.image.resize(x_train, [32, 32])\n",
    "x_test = tf.image.resize(x_test, [32, 32])\n",
    "\n",
    "# 5. Train the Model\n",
    "print(\"Starting training...\")\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995fa7b5-ef63-4aba-99e3-4e508976483c",
   "metadata": {},
   "source": [
    "TOPIC 3: Analyzing AlexNet\n",
    "1. Present an overview of the AlexNet architecture.\n",
    "Explanation: AlexNet was the winner of the 2012 ImageNet challenge and marked the beginning of the \"Deep Learning\" era. It is much deeper and wider than LeNet. It consists of 8 learned layers: 5 convolutional layers and 3 fully connected layers. It was designed to handle high-resolution color images (227x227 pixels).\n",
    "2. Explain the architectural innovations introduced in AlexNet.\n",
    "Explanation:\n",
    "ReLU Activation: It replaced Sigmoid/Tanh with ReLU (Rectified Linear Unit). This solved the vanishing gradient problem and sped up training significantly.\n",
    "Dropout: Introduced in the fully connected layers to randomly \"turn off\" neurons during training. This prevented the model from overfitting (memorizing the data).\n",
    "Data Augmentation: They artificially expanded the dataset by flipping and cropping images to make the model more robust.\n",
    "Overlapping Pooling: Unlike LeNet, AlexNet used pooling windows that overlapped, which slightly reduced error rates.\n",
    "GPU Utilization: It was one of the first models designed specifically to run on parallel GPUs.\n",
    "3. Discuss the role of convolutional layers, pooling layers, and fully connected layers in AlexNet.\n",
    "Explanation:\n",
    "Conv Layers (1-5): The early layers detect simple edges and colors. The deeper layers detect complex shapes and textures (like eyes, wheels, fur).\n",
    "Pooling Layers: Max pooling is used to aggressively downsample the image size to reduce computation while keeping the strongest features.\n",
    "Fully Connected Layers: These act as the \"classifier\" part of the brain. They take the high-level features extracted by the conv layers and determine which class (e.g., \"Dog,\" \"Car\") the image belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb4268-3a4a-4f38-9f62-14a7bbe253ae",
   "metadata": {},
   "source": [
    "4. Implement AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e495afc-6e53-4e7c-9e40-61aeeac56424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amand\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
       "\n",
       " resizing (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Resizing</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,856</span> \n",
       "\n",
       " max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">153,728</span> \n",
       "\n",
       " max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">221,376</span> \n",
       "\n",
       " conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> \n",
       "\n",
       " conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">221,312</span> \n",
       "\n",
       " max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">132,096</span> \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">10,250</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " resizing (\u001b[38;5;33mResizing\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m48\u001b[0m)                     \u001b[38;5;34m5,856\u001b[0m \n",
       "\n",
       " max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m48\u001b[0m)                           \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m153,728\u001b[0m \n",
       "\n",
       " max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m)                    \u001b[38;5;34m221,376\u001b[0m \n",
       "\n",
       " conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m)                    \u001b[38;5;34m331,968\u001b[0m \n",
       "\n",
       " conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m221,312\u001b[0m \n",
       "\n",
       " max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_3 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                         \u001b[38;5;34m132,096\u001b[0m \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                               \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_4 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                       \u001b[38;5;34m1,049,600\u001b[0m \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                               \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_5 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                            \u001b[38;5;34m10,250\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,126,186</span> (8.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,126,186\u001b[0m (8.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,126,186</span> (8.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,126,186\u001b[0m (8.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting AlexNet training...\n",
      "Epoch 1/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 42ms/step - accuracy: 0.9074 - loss: 0.2958 - val_accuracy: 0.9772 - val_loss: 0.0968\n",
      "Epoch 2/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 42ms/step - accuracy: 0.9775 - loss: 0.1006 - val_accuracy: 0.9851 - val_loss: 0.0594\n",
      "Epoch 3/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 39ms/step - accuracy: 0.9825 - loss: 0.0766 - val_accuracy: 0.9874 - val_loss: 0.0504\n",
      "AlexNet implementation complete!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load Data (MNIST)\n",
    "# We reload it to make sure we have a fresh start for the new model\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# 2. Preprocessing\n",
    "# Normalize pixel values\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Add channel dimension (MNIST is grayscale)\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# 3. Define AlexNet Architecture\n",
    "# Note: Standard AlexNet is for 227x227 images.\n",
    "# We will use an Input layer to resize our 28x28 images to 64x64 so AlexNet works.\n",
    "def AlexNet_MNIST():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Input & Resizing Layer\n",
    "    model.add(layers.InputLayer(input_shape=(28, 28, 1)))\n",
    "    model.add(layers.Resizing(64, 64)) \n",
    "\n",
    "    # 1st Convolutional Layer\n",
    "    model.add(layers.Conv2D(filters=48, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "\n",
    "    # 2nd Convolutional Layer\n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "\n",
    "    # 3rd, 4th, 5th Convolutional Layers\n",
    "    model.add(layers.Conv2D(filters=192, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(filters=192, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "    # Max Pooling\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
    "\n",
    "    # Flatten\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Fully Connected Layers with Dropout (Key feature of AlexNet!)\n",
    "    model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# 4. Create and Compile\n",
    "model_alex = AlexNet_MNIST()\n",
    "model_alex.summary() # Check the output to see the bigger architecture\n",
    "\n",
    "model_alex.compile(optimizer='adam', \n",
    "                   loss='sparse_categorical_crossentropy', \n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "# 5. Train\n",
    "print(\"Starting AlexNet training...\")\n",
    "# We train for 3 epochs because AlexNet is larger and slower than LeNet\n",
    "history = model_alex.fit(x_train, y_train, epochs=3, validation_data=(x_test, y_test))\n",
    "\n",
    "print(\"AlexNet implementation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b9be0a-f6ca-43f6-ac67-925a77ccff66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
